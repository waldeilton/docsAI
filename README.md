# docsAI - Assistente de Documenta√ß√£o Inteligente

Um assistente de documenta√ß√£o inteligente que combina web scraping com RAG (Retrieval Augmented Generation). Permite coletar conhecimento de sites, organizar em cole√ß√µes e interagir atrav√©s de chat com os documentos usando LLMs para respostas contextualizadas.

## Funcionalidades

- **Chat com Documentos**: Interface de chat para interagir com documentos coletados
- **Web Scraping**: Coleta automatizada de conte√∫do de sites para uso no RAG
- **Gest√£o de Cole√ß√µes**: Organiza documentos em cole√ß√µes tem√°ticas
- **Visualiza√ß√£o de Documentos**: Visualiza documentos coletados
- **Hist√≥rico de Conversas**: Salva conversas para refer√™ncia futura

## Tecnologias Utilizadas

- **Streamlit**: Interface de usu√°rio
- **LangChain**: Framework para aplica√ß√µes baseadas em LLM
- **OpenAI API**: Modelos de linguagem
- **Firecrawl**: Engine de web scraping
- **FAISS**: Indexa√ß√£o vetorial para recupera√ß√£o de documentos
- **TinyDB**: Armazenamento de dados

## Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ Home.py                         # P√°gina principal (chat)
‚îú‚îÄ‚îÄ pages/                          # P√°ginas adicionais
‚îÇ   ‚îú‚îÄ‚îÄ 1_üîç_Scraping.py            # P√°gina de scraping
‚îÇ   ‚îî‚îÄ‚îÄ 2_üìä_Visualizar.py          # P√°gina de visualiza√ß√£o
‚îú‚îÄ‚îÄ core/                           # M√≥dulos core
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ database.py                 # Opera√ß√µes do banco
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                    # Utilit√°rios
‚îú‚îÄ‚îÄ services/                       # Servi√ßos
‚îÇ   ‚îú‚îÄ‚îÄ ai_service.py               # Servi√ßos de IA
‚îÇ   ‚îú‚îÄ‚îÄ document_service.py         # Servi√ßos de documentos
‚îÇ   ‚îî‚îÄ‚îÄ scraping_service.py         # Servi√ßos de scraping
‚îî‚îÄ‚îÄ data/                           # Dados
    ‚îú‚îÄ‚îÄ conversations/              # Hist√≥rico de conversas
    ‚îî‚îÄ‚îÄ rag/                        # Documentos coletados
```

## Instala√ß√£o

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/waldeilton/docsAI.git
cd docsAI

2. Instale as depend√™ncias:
```bash
# Com Poetry
poetry add streamlit python-dotenv langchain langchain-community langchain-openai faiss-cpu openai streamlit-js-eval tinydb requests unstructured markdown

# Se estiver usando Firecrawl diretamente do GitHub
poetry add git+https://github.com/waldeilton/firecrawl-py.git

# OU com pip
pip install streamlit python-dotenv langchain langchain-community langchain-openai faiss-cpu openai streamlit-js-eval tinydb requests unstructured markdown
```

3. Configure as vari√°veis de ambiente:
```bash
# Crie um arquivo .env na raiz do projeto
echo "OPENAI_API_KEY=sua_chave_api_aqui" > .env
echo "FIRECRAWL_API_KEY=sua_chave_firecrawl_aqui" >> .env
```

## Uso

Execute o aplicativo:
```bash
streamlit run Home.py
```

### Fluxo de trabalho:

1. **P√°gina inicial**:
   - Selecione uma cole√ß√£o de documentos existente
   - Ou crie uma nova com a p√°gina de Scraping

2. **Scraping**:
   - Insira uma URL para extrair conte√∫do
   - Defina um nome para a nova cole√ß√£o
   - Execute o scraping e acompanhe o progresso

3. **Chat**:
   - Selecione uma cole√ß√£o para conversar
   - Fa√ßa perguntas sobre os documentos 
   - As respostas ser√£o geradas com base nos documentos da cole√ß√£o

4. **Visualiza√ß√£o**:
   - Explore os documentos coletados
   - Veja estat√≠sticas das suas cole√ß√µes

## Notas sobre o Streamlit Multipage

Este projeto usa o sistema nativo de p√°ginas do Streamlit:

- A p√°gina principal √© `Home.py` na raiz do projeto
- P√°ginas adicionais ficam na pasta `pages/` com prefixos num√©ricos para definir a ordem
- A navega√ß√£o √© autom√°tica pela barra lateral gerada pelo Streamlit
- Compartilhamento de estado entre p√°ginas √© feito via `st.session_state`

## Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Por favor, abra um issue primeiro para discutir o que voc√™ gostaria de mudar.

## Licen√ßa

[MIT](LICENSE)